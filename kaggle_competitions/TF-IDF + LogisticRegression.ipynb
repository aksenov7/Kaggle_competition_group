{"cells":[{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Импорт библиотек\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\nimport string\n\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#скачиваем датасет\ntrain = pd.read_csv('../input/nlp-getting-started/train.csv')\ntest = pd.read_csv('../input/nlp-getting-started/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = ['The weather is sunny', 'The weather is partly sunny and partly cloudy.']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\nvectorizer.fit(sentences)\nvectorizer.vocabulary_\nvectorizer.transform(sentences).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#стопслова\nstopwords = stopwords.words('english')\n\ncount_vectorizer = CountVectorizer(stop_words = stopwords)\ncount_vectorizer.fit(train['text'])\n\ntrain_vectors = count_vectorizer.transform(train['text'])\ntest_vectors = count_vectorizer.transform(test['text'])\n\ntrain_vectors.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mindf/maxdf\ncount_vectorizer = CountVectorizer(stop_words = stopwords, min_df=2 ,max_df=0.8)\ncount_vectorizer.fit(train['text'])\n\ntrain_vectors = count_vectorizer.transform(train['text'])\ntest_vectors = count_vectorizer.transform(test['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Убираем лишние символы регулярками\n\ndef custom_preprocessor(text):\n\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub(\"\\\\W\",\" \",text) # remove special chars\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    \n    return text\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(list(train['text']),preprocessor=custom_preprocessor)\n\ntrain_vectors = count_vectorizer.fit_transform(list(train['text']))\ntest_vectors = count_vectorizer.transform(list(test['text']))\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(list(train['text']),preprocessor=custom_preprocessor,ngram_range=(1,2))\n\ntrain_vectors = count_vectorizer.fit_transform(list(train['text']))\ntest_vectors = count_vectorizer.transform(list(test['text']))\n\nlist(count_vectorizer.vocabulary_)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(list(train['text']),preprocessor=custom_preprocessor,ngram_range=(1,3),\n                                  analyzer='char_wb')\n\ntrain_vectors = count_vectorizer.fit_transform(list(train['text']))\ntest_vectors = count_vectorizer.transform(list(test['text']))\n\nprint(list(count_vectorizer.vocabulary_)[:20])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(token_pattern=r'\\w{1,}',\n                   ngram_range=(1, 2), stop_words = stopwords,preprocessor=custom_preprocessor)\ncount_vectorizer .fit(train['text'])\n\ntrain_vectors = count_vectorizer.transform(train['text'])\ntest_vectors = count_vectorizer.transform(test['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#logistic Regression sklearn\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(C=1.0)\nscores = model_selection.cross_val_score(clf, train_vectors, train[\"target\"], cv=5, scoring=\"f1\")\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(train_vectors, train[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"] = clf.predict(test_vectors)\nsample_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TF-IDF\ntfidf = TfidfVectorizer(analyzer='word',token_pattern=r'\\w{1,}',max_features=5000)\ntrain_tfidf = tfidf.fit_transform(train['text'])\ntest_tfidf = tfidf.transform(test[\"text\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(analyzer='word',ngram_range=(2,3),token_pattern=r'\\w{1,}',max_features=5000)\ntrain_tfidf = tfidf.fit_transform(train['text'])\ntest_tfidf = tfidf.transform(test[\"text\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(analyzer='char',ngram_range=(1,3),token_pattern=r'\\w{1,}',max_features=5000)\ntrain_tfidf = tfidf.fit_transform(train['text'])\ntest_tfidf = tfidf.transform(test[\"text\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model\ntfidf_vectorizer = TfidfVectorizer( min_df=3,  max_features=None,analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = stopwords)\n\ntrain_tfidf = tfidf.fit_transform(train['text'])\ntest_tfidf = tfidf.transform(test[\"text\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(C=1.0)\nscores = model_selection.cross_val_score(clf, train_tfidf, train[\"target\"], cv=5, scoring=\"f1\")\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression + TF-IDF\nclf.fit(train_tfidf, train[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}