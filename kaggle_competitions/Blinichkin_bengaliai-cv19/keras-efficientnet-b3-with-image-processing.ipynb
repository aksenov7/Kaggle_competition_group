{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/kerasefficientnetb3/efficientnet-1.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0) (0.16.2)\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0) (1.0.8)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (5.4.1)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (1.1.1)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (2.6.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (2.4)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (1.4.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (3.0.3)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.18.1)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (2.10.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0) (4.4.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (2.4.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (2.8.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.14.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (45.2.0.post20200210)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.0.0\r\n"
     ]
    }
   ],
   "source": [
    "# Install EfficientNet B3\n",
    "!pip install '../input/kerasefficientnetb3/efficientnet-1.0.0-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Lambda\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import efficientnet.keras as efn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ширина изображения\n",
    "IMAGE_WIDTH = 236\n",
    "# Высота изображения\n",
    "IMAGE_HEIGHT = 137\n",
    "# Коэффициент масштабирования\n",
    "FACTOR = 0.7\n",
    "# Каналы\n",
    "CHANNELS = 3\n",
    "# Размер пакета\n",
    "BATCH_SIZE = 16\n",
    "# Новая ширина изображения\n",
    "IMAGE_WIDTH_NEW = int(IMAGE_WIDTH * FACTOR)\n",
    "# Новая высота изображения\n",
    "IMAGE_HEIGHT_NEW = int(IMAGE_HEIGHT * FACTOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageProcessing(image):\n",
    "    \"\"\"\n",
    "    Обработка изображения.\n",
    "    \n",
    "    image - изображение\n",
    "    return - обработанное изображение\n",
    "    \"\"\"\n",
    "    \n",
    "    # Invert\n",
    "    image = 255 - image\n",
    "\n",
    "    # Normalize\n",
    "    image = (image * (255.0 / image.max())).astype(np.uint8)\n",
    "\n",
    "    # Resize\n",
    "    image = image.reshape(IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    image = cv2.resize(image, (IMAGE_WIDTH_NEW, IMAGE_HEIGHT_NEW), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    return image  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized mean pool - GeM\n",
    "gmExp = tf.Variable(3.0, dtype = tf.float32)\n",
    "def generalizedMeanPool(X):\n",
    "    pool = (tf.reduce_mean(tf.abs(X**(gmExp)), axis = [1, 2], keepdims = False) + 1.e-7)**(1./gmExp)\n",
    "    \n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(inputShape):\n",
    "    \"\"\"\n",
    "    Создание модели блока свертки.\n",
    "    \n",
    "    inputShape - размер и канальность изображения\n",
    "    return - модель\n",
    "    \"\"\"\n",
    "    \n",
    "    # Входной слой\n",
    "    input = Input(shape=inputShape)\n",
    "    # Создание и компиляция модели\n",
    "    xModel = efn.EfficientNetB3(weights=None, include_top=False, input_tensor=input, pooling=None, classes=None)\n",
    "    \n",
    "    # Разморозка всех слоев\n",
    "    for layer in xModel.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Обобщенный средний пул\n",
    "    lambdaLayer = Lambda(generalizedMeanPool)\n",
    "    lambdaLayer.trainable_weights.extend([gmExp])\n",
    "    dense = lambdaLayer(xModel.output)\n",
    "    \n",
    "    # Выход нейронной сети отвечающий за классификацию графем\n",
    "    graphemeRoot = Dense(168, activation = 'softmax', name = 'root')(dense)\n",
    "    # Выход нейронной сети отвечающий за классификацию гласных диакректических знаков\n",
    "    vowelDiacritic = Dense(11, activation = 'softmax', name = 'vowel')(dense)\n",
    "    # Выход нейронной сети отвечающий за классификацию согласных диакректических знаков\n",
    "    consonantDiacritic = Dense(7, activation = 'softmax', name = 'consonant')(dense)\n",
    "\n",
    "    # Создание модели\n",
    "    model = Model(inputs = xModel.input, outputs = [graphemeRoot, vowelDiacritic, consonantDiacritic])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание моделей\n",
    "model1 = createModel(inputShape = (IMAGE_HEIGHT_NEW, IMAGE_WIDTH_NEW, CHANNELS))\n",
    "model2 = createModel(inputShape = (IMAGE_HEIGHT_NEW, IMAGE_WIDTH_NEW, CHANNELS))\n",
    "model3 = createModel(inputShape = (IMAGE_HEIGHT_NEW, IMAGE_WIDTH_NEW, CHANNELS))\n",
    "model4 = createModel(inputShape = (IMAGE_HEIGHT_NEW, IMAGE_WIDTH_NEW, CHANNELS))\n",
    "model5 = createModel(inputShape = (IMAGE_HEIGHT_NEW, IMAGE_WIDTH_NEW, CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка весовых коэффициентов моделей\n",
    "model1.load_weights(\"../input/kerasefficientnetb3/Train1_model_59.h5\")\n",
    "model2.load_weights(\"../input/kerasefficientnetb3/Train1_model_66.h5\")\n",
    "model3.load_weights(\"../input/kerasefficientnetb3/Train1_model_68.h5\")\n",
    "model4.load_weights(\"../input/kerasefficientnetb3/Train1_model_57.h5\")\n",
    "model5.load_weights(\"../input/kerasefficientnetb3/Train1_model_70.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, X, batch_size = 16, img_size = (512, 512, 3), *args, **kwargs):\n",
    "        self.X = X\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return int(ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "    \n",
    "    def __data_generation(self, indices):\n",
    "        X = np.empty((self.batch_size, *self.img_size))\n",
    "        \n",
    "        for i, index in enumerate(indices):\n",
    "            image = self.X[index]\n",
    "            image = np.stack((image,)*CHANNELS, axis=-1)\n",
    "            image = image.reshape(-1, IMAGE_HEIGHT_NEW, IMAGE_WIDTH_NEW, CHANNELS)\n",
    "            \n",
    "            X[i,] = image\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "components = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n",
    "\n",
    "# Список предсказаний модели\n",
    "targets = []\n",
    "# Список id меток предсказаний\n",
    "rowIds = []\n",
    "# Количество файлов\n",
    "numberFiles = 4\n",
    "\n",
    "# Цикл по тестовым файлам\n",
    "for i in range(numberFiles):\n",
    "    # Test Files Placeholder\n",
    "    testFiles = []\n",
    "    \n",
    "    # Загрузка тестового набора изображений\n",
    "    df = pd.read_parquet(f\"/kaggle/input/bengaliai-cv19/test_image_data_{i}.parquet\")\n",
    "    # Получение идентификаторов изображений\n",
    "    imageIds = df['image_id'].values \n",
    "    # Удаление ключа 'image_id'\n",
    "    df = df.drop(['image_id'], axis = 1)\n",
    "    \n",
    "    X = []\n",
    "    # Цикл обработки строк фрейма данных\n",
    "    for imageId, index in zip(imageIds, range(df.shape[0])):\n",
    "        # Добавление идентификатора изображения в список\n",
    "        testFiles.append(imageId)\n",
    "        # Получение изображения\n",
    "        image = df.loc[df.index[index]].values\n",
    "        # Обработка изображения\n",
    "        image = imageProcessing(image)\n",
    "        # Добавление преобразованного изображения в список\n",
    "        X.append(image.reshape(-1))\n",
    "    \n",
    "    # Генератор данных\n",
    "    dataGeneratorTest = TestDataGenerator(X, batch_size=BATCH_SIZE, img_size=(IMAGE_HEIGHT_NEW, IMAGE_WIDTH_NEW, CHANNELS))\n",
    "        \n",
    "    # Выполнение предсказания\n",
    "    preds1 = model1.predict_generator(dataGeneratorTest, verbose = 1)\n",
    "    preds2 = model2.predict_generator(dataGeneratorTest, verbose = 1)\n",
    "    preds3 = model3.predict_generator(dataGeneratorTest, verbose = 1)\n",
    "    preds4 = model4.predict_generator(dataGeneratorTest, verbose = 1)\n",
    "    preds5 = model5.predict_generator(dataGeneratorTest, verbose = 1)\n",
    "    \n",
    "    # Цикл после прогнозирования    \n",
    "    for i, imageId in zip(range(len(testFiles)), testFiles):\n",
    "        for subi, col in zip(range(len(preds1)), components):\n",
    "            subPreds1 = preds1[subi]\n",
    "            subPreds2 = preds2[subi]\n",
    "            subPreds3 = preds3[subi]\n",
    "            subPreds4 = preds4[subi]\n",
    "            subPreds5 = preds5[subi]\n",
    "            \n",
    "            rowIds.append(str(imageId) + '_' + col)\n",
    "            # Установка прозноза со средним значением пяти прогнозов\n",
    "            subPredValue = np.argmax((subPreds1[i] + subPreds2[i] + subPreds3[i] + subPreds4[i] + subPreds5[i]) / 5)\n",
    "            targets.append(subPredValue)\n",
    "    \n",
    "    # Очистка\n",
    "    del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         row_id  target\n",
      "0          Test_0_grapheme_root       3\n",
      "1        Test_0_vowel_diacritic       0\n",
      "2    Test_0_consonant_diacritic       0\n",
      "3          Test_1_grapheme_root      93\n",
      "4        Test_1_vowel_diacritic       2\n",
      "5    Test_1_consonant_diacritic       0\n",
      "6          Test_2_grapheme_root      19\n",
      "7        Test_2_vowel_diacritic       0\n",
      "8    Test_2_consonant_diacritic       0\n",
      "9          Test_3_grapheme_root     115\n",
      "10       Test_3_vowel_diacritic       0\n",
      "11   Test_3_consonant_diacritic       0\n",
      "12         Test_4_grapheme_root      55\n",
      "13       Test_4_vowel_diacritic       4\n",
      "14   Test_4_consonant_diacritic       0\n",
      "15         Test_5_grapheme_root     115\n",
      "16       Test_5_vowel_diacritic       2\n",
      "17   Test_5_consonant_diacritic       0\n",
      "18         Test_6_grapheme_root     147\n",
      "19       Test_6_vowel_diacritic       9\n",
      "20   Test_6_consonant_diacritic       5\n",
      "21         Test_7_grapheme_root     137\n",
      "22       Test_7_vowel_diacritic       7\n",
      "23   Test_7_consonant_diacritic       0\n",
      "24         Test_8_grapheme_root     119\n",
      "25       Test_8_vowel_diacritic       9\n",
      "26   Test_8_consonant_diacritic       0\n",
      "27         Test_9_grapheme_root     133\n",
      "28       Test_9_vowel_diacritic      10\n",
      "29   Test_9_consonant_diacritic       0\n",
      "30        Test_10_grapheme_root     148\n",
      "31      Test_10_vowel_diacritic       1\n",
      "32  Test_10_consonant_diacritic       4\n",
      "33        Test_11_grapheme_root      21\n",
      "34      Test_11_vowel_diacritic       2\n",
      "35  Test_11_consonant_diacritic       0\n"
     ]
    }
   ],
   "source": [
    "# Создание и сохранение файла ответов\n",
    "submit_df = pd.DataFrame({'row_id':rowIds, 'target':targets}, columns = ['row_id', 'target'])\n",
    "submit_df.to_csv('submission.csv', index = False)\n",
    "print(submit_df.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение моделей\n",
    "model1.save(\"model1.h5\")\n",
    "model2.save(\"model2.h5\")\n",
    "model3.save(\"model3.h5\")\n",
    "model4.save(\"model4.h5\")\n",
    "model5.save(\"model5.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
