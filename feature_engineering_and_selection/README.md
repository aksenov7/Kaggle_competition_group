# feature engineering and selection
  Тут хранятся алгоритмы для создания признаков (для всех видов данных) и анализа весомости этих признаков по отношению к решению задачи, а также некая предварительная обработка признаков:
  - предусмотреть различные стратегии заполнения пропусков в данных
  - анализ выбросов и их сглаживание
  - нормализация данных (существует много стандартных инструментов)
  - генерация признаков для цифровых данных
  - генерация признаков для категориальных данных (все виды кодирования)
  - генерация признаков для временных данных
  - другие стратегии, которые найдете (как отдельный блок, можно расмотреть инструменты автоматической генерации признаков)
  - встроить некую базовую модель (ее обсудим позже), на основе, которой будет происходить тестирование новых признаков и их выбор или отклонение
  - базовая модель обучается на просто входных данных, какие есть, получаем точность по заданной метрике - это база от которой будем отталкиваться (предусмотреть передачу параметром метрики качества и собственно базовой модели)
  - рассмотреть стратегии добавления новых признаков (может оказаться, что каждая по отдельности добавляет качество, но они перекрывают влияние друг друга и какую-то стоит выбросить).
  - предусмотреть передачу лучших выбранных признаков и модели на основе, которой они были выбраны, дальше группе которая занимается выбором лучшей модели. Но возможен и вариант наоборот, когда от них приходит модель с некими параметрами и нужно на основе нее тестить и выбирать признаки
  
  
- https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection
- https://www.machinelearningtutorial.net/2017/06/17/feature-engineering-in-machine-learning/
- https://github.com/topepo/FES
 - Заполняем пропущенные данные 
https://towardsdatascience.com/using-pandas-transform-and-apply-to-deal-with-missing-data-on-a-group-level-cb6ccf060531
- Ищем и удаляем выбросы 
https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba
  
