{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn import datasets\nimport seaborn as sns\nfrom sklearn.covariance import EllipticEnvelope\nfrom sklearn.datasets import make_blobs\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Датасет титаник для проверок"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/titanic/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Датасет M5 для проверок"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Работа со временем"},{"metadata":{},"cell_type":"markdown","source":"**Функция приведения значений unixtime → datetime**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Входные данные - колонка в unixtime для датафрейма с названием df.\n#Выходные данные - в df колонка из unixtime преобразуется в datetime.\ndef unixtime_to_datetime(unixtime_colomn):\n    df[unixtime_colomn] = pd.to_datetime(df[unixtime_colomn], unit='s')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Разбиваем дату на год/месяц/день недели (число 1-7 + название дня)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def datetime_into_colums(column): #На входе передаётся колонка datetime, над которой производится преобразование в год/месяц/день\n    \n    df['column'] = pd.to_datetime(df['column'],format='%d-%m-%Y %H:%M')\n\n    df['year']=df['column'].dt.year \n    df['month']=df['column'].dt.month \n    df['day']=df['column'].dt.day\n    df['dayofweek_num']=df['column'].dt.dayofweek  \n    df['dayofweek_name']=df['column'].dt.weekday_name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Также обработать данные типа datetime можно наиболее универсальным способом используя парсер из библиотеки dateutil. Она позволяет передавать на вход парсеру дату в любом формате и переводить в один формат.\nПример кода ниже:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from dateutil import parser\n\ndate = parser.parse('2011/12/15')\n# Это также можно использовать для всех данных","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Заполнение числовых пропусков в таблице"},{"metadata":{},"cell_type":"markdown","source":"**Выделение null-значений в датафрейме**\n\nНа вход передаётся тип вставки значения ('value', 'mean', 'equal'), который отвечает за подстановку значения (см.комментарии)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_value (type_insert, column_na, groupby_parametr): \n        #Выделение null-значений в датафрейме\n    if type_insert=='value':\n        df[column_na] = df[column_na].fillna(-999) #пустые значения можно выделить значением, которое не встречается в df, таким образом мы указываем, что в данном значении раньше был null\n        #Заполнение null-значений средним значением из имеющихся\n    if type_insert=='mean':\n        df[column_na] = df.groupby(groupby_parameter)[column_na].transform(\n        lambda grp: grp.fillna(np.mean(grp))\n    )\n        #Замена null-значений уже существующими значениями\n    if type_insert=='equal':\n        df[column_na] = df[column_na].ffill().bfill()\n\nfill_value('value', 'Age', '')\ndf","execution_count":43,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Работа с выбросами, значениями нетипичными для датафрейма (ошибками в источнике данных)"},{"metadata":{"trusted":true},"cell_type":"code","source":"Построение графиков доступно в библиотеке seaborn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2 страдегии работы с выбросами**\n\n1 - отбросить строки с выбросами\n\n//q = df['Age'].quantile(0.80)"},{"metadata":{},"cell_type":"markdown","source":"Находим выбросы, у которых квантиль менее 10% и более 90% и отбрасываем их"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_outburst(column): #На входе передаём название колонки с выбросами, которые будут исключены\n    low_fence = df[column].quantile(0.10)\n    high_fence = df[column].quantile(0.90)\n    df_out = df.loc[(df[column] > low_fence) & (df[column] < high_fence)]\n    return df_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out = find_outburst('Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df_out['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2 - Создание признака исключения для значений-выбросов"},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_feat_outburst(column): #На входе передаём название колонки с выбросами, по которым будет создан признак\n    low_fence = df[column].quantile(0.10)\n    high_fence = df[column].quantile(0.90)\n    df['Outburst'] = np.where((df[column] > low_fence) & (df[column] < high_fence), 0, 1)\n    return df","execution_count":59,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Категориальные признаки"},{"metadata":{},"cell_type":"markdown","source":"**Полезные ссылки** \n[категориальные признаки](https://dyakonov.org/2016/08/03/python-%D0%BA%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5-%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%B8/)"},{"metadata":{},"cell_type":"markdown","source":"**Нахождение категориальных признаков**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_cat(df): #На входе передаём датафрейм\n    for name in df.columns:\n        cat_feat = ''\n        cat_feat += name\n        if (type(df[name][0])== str): #Проверяем, что в элементе 0 у столбца строка\n            cat_feat += ' строка'\n        if (df[name].nunique()<=10): #Находим количество уникальных значений в датафрейме, число 10 изменяем при необходимости - это поможет выбрать категориальные значения\n            cat_feat += ' менее 10 уникальных значений'\n        if (cat_feat!=name):\n            print(cat_feat) #Получаем уникальные значения в колонках по типу указанному в функции\n            \nfind_cat(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Создаём новые категориальные признаки**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Объединение 2ух значений (конъюнция)\ndef make_feat_conj(df, cat1, cat2): #на входе передаём название датафрейма и названия колонок, над которыми совершается преобразование\n    df[cat1 + '+' + cat2] = df[cat1].astype(str) + '+' + df[cat2].astype(str)\n    return df\nmake_feat_conj(df, 'Sex', 'Embarked')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Есть простейший кодировщий sklearn.preprocessing.LabelEncoder, который каждой категории сопоставляет некоторое целое число (собственно, номер категории). Даже если бы его не было, то такую кодировку несложно написать самому с помощью функции map. Для этого предварительно задаётся словарь, в котором указывается, что и чем кодировать.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(df.Sex)\ndf['Sex_le'] = le.transform(df.Sex)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ручное кодирование через map"},{"metadata":{"trusted":true},"cell_type":"code","source":"dct = {'male': 0, 'female': 1}\n\ndf['Sex_le'] = df['Sex'].map(dct)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dummy-кодирование**"},{"metadata":{},"cell_type":"markdown","source":"Есть простейший метод кодирования, его часто называют наивным / глупым (dummy) кодированием или one-hot-кодированием. Для кодируемого категориального признака создаются N новых признаков, где N — число категорий. Каждый i-й новый признак — бинарный характеристический признак i-й категории.\n\nПредположим, что некоторый признак может принимать 10 разных значений. В этом случае OneHot подразумевает создание 10 признаков, все из которых равны нулю за исключением одного. На позицию, соответствующую численному значению признака мы помещаем 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Работает только с целочисленными значениями\nfrom sklearn.preprocessing import OneHotEncoder\njust_dummies = pd.get_dummies(df['Embarked'])\n#где df['dummy'] - столбец, который нужно закодировать\n#Конкатенируешь к датафрейму df закодированные столбцы\nstep_1 = pd.concat([df, just_dummies], axis=1)      \n#Удаляешь столбец на основе которого строил признаки\nstep_1.drop(['Embarked'], inplace=True, axis=1)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Среднее значение 2ух столбцов"},{"metadata":{"trusted":true},"cell_type":"code","source":"def code_mean(df, cat_feat, real_feat): #на входе передаём название датафрейма и названия колонок, над которыми совершается преобразование\n    return(df[cat_feat].map(df.groupby(cat_feat)[real_feat].mean()))\n\ndf['Sex_Age_mean'] = code_mean(df, 'Sex', 'Age')\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Хэширование признаков**"},{"metadata":{},"cell_type":"markdown","source":"Реальные данные могут оказаться гораздо более динамичными, и мы не всегда можем рассчитывать, что категориальные признаки не будут принимать новых значений. Все это сильно затрудняет использование уже обученных моделей на новых данных. Кроме того, LabelEncoder подразумевает предварительный анализ всей выборки и хранение построенных отображений в памяти, что затрудняет работу в режиме больших данных.\n\nДля решения этих проблем существует более простой подход к векторизации категориальных признаков, основанный на хэшировании.\n\nХэш-функции могут помочь нам в задаче поиска уникальных кодов для различных значений признака.\nНа примере с полом пассажира это может выглядеть так:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отрицательные и большие по модулю значения нам не подойдут, ограничим область значений хэш-функции:\nhash_space = 25\n\nfor s in ('female', 'male'): \n    print(s, '->', hash(s) % hash_space)","execution_count":41,"outputs":[{"output_type":"stream","text":"female -> 23\nmale -> 1\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"С помощью хэширования, к примеру, работают некоторые облачные вычислительные сервера типа Kaggle. В них некоторым образом анализируется исходный код программ, вычисляется хэш и подбирается наиболее подходящий сервер для работы конкретной программы."},{"metadata":{},"cell_type":"markdown","source":"# Нормализация признаков"},{"metadata":{},"cell_type":"markdown","source":"**Шкалирование признаков**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaler(scaler_type, column1, column2): #На вход подаётся строка, тип scaler = Robust или Standart и 2 колонки в датафрейме\n    x = df[[column1, column2]]\n    if scaler_type=='Robust':\n        # Создать шкалировщик\n        scaler = preprocessing.RobustScaler()\n        # Преобразовать признак\n        standardized = scaler.fit_transform (x)\n    if scaler_type=='Standart':\n        # Создать шкалировщик\n        scaler = preprocessing.StandardScaler()\n        # Преобразовать признак\n        standardized = scaler.fit_transform (x)\n    return standardized #на выходе получаем стандартизированную колонку\nscaler('Robust', 'Age', 'Pclass')","execution_count":56,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}